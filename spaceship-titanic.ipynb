{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jackren000/spaceship-titanic?scriptVersionId=162295150\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"5bca05d0","metadata":{"papermill":{"duration":0.009683,"end_time":"2024-02-09T12:05:53.58015","exception":false,"start_time":"2024-02-09T12:05:53.570467","status":"completed"},"tags":[]},"source":["### Define Objectives:  \n","*In this competition, the task is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly.*"]},{"cell_type":"code","execution_count":1,"id":"93524a63","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-09T12:05:53.600136Z","iopub.status.busy":"2024-02-09T12:05:53.599833Z","iopub.status.idle":"2024-02-09T12:05:58.966766Z","shell.execute_reply":"2024-02-09T12:05:58.965934Z"},"papermill":{"duration":5.379183,"end_time":"2024-02-09T12:05:58.969046","exception":false,"start_time":"2024-02-09T12:05:53.589863","status":"completed"},"tags":[]},"outputs":[],"source":["#### import libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","from sklearn.model_selection import train_test_split  # automatic splitting method\n","from sklearn.model_selection import GridSearchCV  # cross validation\n","from sklearn.linear_model import LogisticRegression  # logistic regression classifier\n","from sklearn.neighbors import KNeighborsClassifier  # k-nearest neighbors classifier\n","from sklearn.ensemble import RandomForestClassifier  # random forest classifier\n","from sklearn.metrics import accuracy_score  # accuracy scoring metric\n","from sklearn.metrics import classification_report  # classification performance report\n","from sklearn.preprocessing import StandardScaler  # standard scaler for normalization\n","from sklearn.preprocessing import MinMaxScaler  # min-max scaler for normalization\n","\n","# import PyTorch for Deep Learning\n","import torch\n","# import neural network\n","from torch import nn\n","# import relative math functions\n","import torch.nn.functional as F\n","# import PyTorch DataLoader\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","id":"12c94134","metadata":{"papermill":{"duration":0.010004,"end_time":"2024-02-09T12:05:58.988699","exception":false,"start_time":"2024-02-09T12:05:58.978695","status":"completed"},"tags":[]},"source":["### Data Collection:  \n","*Load data into pandas DataFrame for further analysis.*"]},{"cell_type":"code","execution_count":2,"id":"df5da0ce","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.00881Z","iopub.status.busy":"2024-02-09T12:05:59.008371Z","iopub.status.idle":"2024-02-09T12:05:59.090025Z","shell.execute_reply":"2024-02-09T12:05:59.089254Z"},"papermill":{"duration":0.093855,"end_time":"2024-02-09T12:05:59.092054","exception":false,"start_time":"2024-02-09T12:05:58.998199","status":"completed"},"tags":[]},"outputs":[],"source":["#### load the file\n","DIR_PATH = '/kaggle/input/spaceship-titanic'\n","train = pd.read_csv(os.path.join(DIR_PATH, 'train.csv'))\n","test = pd.read_csv(os.path.join(DIR_PATH, 'test.csv'))"]},{"cell_type":"markdown","id":"dd0f4832","metadata":{"papermill":{"duration":0.008728,"end_time":"2024-02-09T12:05:59.109968","exception":false,"start_time":"2024-02-09T12:05:59.10124","status":"completed"},"tags":[]},"source":["### Data Cleaning:  \n","*Clean the unhelpful columns, NaN value, duplicates and inconsistencies.*"]},{"cell_type":"code","execution_count":3,"id":"997aa1dc","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.129253Z","iopub.status.busy":"2024-02-09T12:05:59.12846Z","iopub.status.idle":"2024-02-09T12:05:59.156932Z","shell.execute_reply":"2024-02-09T12:05:59.155704Z"},"papermill":{"duration":0.040134,"end_time":"2024-02-09T12:05:59.158843","exception":false,"start_time":"2024-02-09T12:05:59.118709","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8693 entries, 0 to 8692\n","Data columns (total 14 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   PassengerId   8693 non-null   object \n"," 1   HomePlanet    8492 non-null   object \n"," 2   CryoSleep     8476 non-null   object \n"," 3   Cabin         8494 non-null   object \n"," 4   Destination   8511 non-null   object \n"," 5   Age           8514 non-null   float64\n"," 6   VIP           8490 non-null   object \n"," 7   RoomService   8512 non-null   float64\n"," 8   FoodCourt     8510 non-null   float64\n"," 9   ShoppingMall  8485 non-null   float64\n"," 10  Spa           8510 non-null   float64\n"," 11  VRDeck        8505 non-null   float64\n"," 12  Name          8493 non-null   object \n"," 13  Transported   8693 non-null   bool   \n","dtypes: bool(1), float64(6), object(7)\n","memory usage: 891.5+ KB\n"]}],"source":["train.info()"]},{"cell_type":"markdown","id":"951594df","metadata":{"papermill":{"duration":0.00982,"end_time":"2024-02-09T12:05:59.177864","exception":false,"start_time":"2024-02-09T12:05:59.168044","status":"completed"},"tags":[]},"source":["Note: All feature columns (exclude ID) have missing values."]},{"cell_type":"code","execution_count":4,"id":"b69a951f","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.196972Z","iopub.status.busy":"2024-02-09T12:05:59.196505Z","iopub.status.idle":"2024-02-09T12:05:59.220502Z","shell.execute_reply":"2024-02-09T12:05:59.219584Z"},"papermill":{"duration":0.035582,"end_time":"2024-02-09T12:05:59.222326","exception":false,"start_time":"2024-02-09T12:05:59.186744","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>HomePlanet</th>\n","      <th>CryoSleep</th>\n","      <th>Cabin</th>\n","      <th>Destination</th>\n","      <th>Age</th>\n","      <th>VIP</th>\n","      <th>RoomService</th>\n","      <th>FoodCourt</th>\n","      <th>ShoppingMall</th>\n","      <th>Spa</th>\n","      <th>VRDeck</th>\n","      <th>Name</th>\n","      <th>Transported</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0001_01</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>B/0/P</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>39.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Maham Ofracculy</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0002_01</td>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>F/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>24.0</td>\n","      <td>False</td>\n","      <td>109.0</td>\n","      <td>9.0</td>\n","      <td>25.0</td>\n","      <td>549.0</td>\n","      <td>44.0</td>\n","      <td>Juanna Vines</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0003_01</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>58.0</td>\n","      <td>True</td>\n","      <td>43.0</td>\n","      <td>3576.0</td>\n","      <td>0.0</td>\n","      <td>6715.0</td>\n","      <td>49.0</td>\n","      <td>Altark Susent</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0003_02</td>\n","      <td>Europa</td>\n","      <td>False</td>\n","      <td>A/0/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>33.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>1283.0</td>\n","      <td>371.0</td>\n","      <td>3329.0</td>\n","      <td>193.0</td>\n","      <td>Solam Susent</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0004_01</td>\n","      <td>Earth</td>\n","      <td>False</td>\n","      <td>F/1/S</td>\n","      <td>TRAPPIST-1e</td>\n","      <td>16.0</td>\n","      <td>False</td>\n","      <td>303.0</td>\n","      <td>70.0</td>\n","      <td>151.0</td>\n","      <td>565.0</td>\n","      <td>2.0</td>\n","      <td>Willy Santantines</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n","0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n","1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n","2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n","3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n","4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n","\n","   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n","0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n","1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n","2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n","3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n","4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n","\n","   Transported  \n","0        False  \n","1         True  \n","2        False  \n","3        False  \n","4         True  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":5,"id":"176da63e","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.24334Z","iopub.status.busy":"2024-02-09T12:05:59.243047Z","iopub.status.idle":"2024-02-09T12:05:59.360097Z","shell.execute_reply":"2024-02-09T12:05:59.359119Z"},"papermill":{"duration":0.129481,"end_time":"2024-02-09T12:05:59.362171","exception":false,"start_time":"2024-02-09T12:05:59.23269","status":"completed"},"tags":[]},"outputs":[],"source":["#### define the clean data function\n","def data_cleaning(df):\n","    ######################## data cleaning ################################\n","    # list of categorical features to fill with mode\n","    categorical_features = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n","    # list of numerical features to fill with mean\n","    numerical_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n","\n","    # fill missing values for categorical features with mode\n","    for feature in categorical_features:\n","        df[feature] = df[feature].fillna(df[feature].mode()[0])\n","    # fill missing values for numerical features with mean\n","    for feature in numerical_features:\n","        df[feature] = df[feature].fillna(df[feature].mean())\n","        \n","    ######################### feature engineering ##########################\n","    # define the age bins\n","#     age_bins = [0, 12, 18, 35, 60, float('inf')]\n","    # assign a number for each age group\n","#     age_labels = [1, 2, 3, 4, 5]  # These numbers correspond to 'Child', 'Teen', 'Young Adult', 'Adult', 'Senior'\n","    # create the 'AgeGroup' column\n","#     df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n","\n","    # split the 'Cabin' column into 'Deck', 'Num', and 'Side'\n","    df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('/', expand=True)\n","    # fill NaN values in 'Deck' with the mode of the 'Deck' column\n","#     df['Deck'] = df['Deck'].fillna(df['Deck'].mode()[0])\n","    # map 'Deck' column\n","#     df['Deck'] = df['Deck'].map({'B':1,'F':2,'A':3,'G':4,'E':5,'D':6,'C':7,'T':8})\n","    # fill NaN values in 'Num' with the mode of the 'Num' column\n","    df['Num'] = df['Num'].fillna(df['Num'].mode()[0])\n","    # convert 'Num' into an integer\n","    df['Num'] = df['Num'].astype(int)\n","    # fill NaN values in 'Side' with the mode of the 'Side' column\n","    df['Side'] = df['Side'].fillna(df['Side'].mode()[0])\n","    # map 'P' to Port (0) and 'S' to Starboard (1)\n","    df['Side'] = df['Side'].map({'P': 0, 'S': 1})\n","    # map 'HomePlanet'\n","    df['HomePlanet'] = df['HomePlanet'].map({'Europa':1,'Earth':2,'Mars':3})\n","    # map 'Destination'\n","    df['Destination'] = df['Destination'].map({'TRAPPIST-1e':1,'PSO J318.5-22':2,'55 Cancri e':3})\n","    # perform one-hot encoding on 'HomePlanet' and 'Destination' columns\n","#     df = pd.get_dummies(df, columns=['HomePlanet', 'Destination'])\n","    # extract the group identifier from 'PassengerId'\n","    group = df['PassengerId'].str.split('_').str[0]\n","    # create a dictionary with group counts\n","    group_size_dict = group.value_counts().to_dict()\n","    # map the group size to each passenger\n","    df['group_size'] = group.map(group_size_dict)\n","    # drop 'Name' and 'Cabin' columns from the DataFrame\n","    df = df.drop(['PassengerId', 'Name', 'Cabin', 'Deck'], axis=1)\n","        \n","    return df"]},{"cell_type":"code","execution_count":6,"id":"b41e3d23","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.386416Z","iopub.status.busy":"2024-02-09T12:05:59.385714Z","iopub.status.idle":"2024-02-09T12:05:59.462118Z","shell.execute_reply":"2024-02-09T12:05:59.460983Z"},"papermill":{"duration":0.089136,"end_time":"2024-02-09T12:05:59.464108","exception":false,"start_time":"2024-02-09T12:05:59.374972","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_27/3849463590.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df[feature] = df[feature].fillna(df[feature].mode()[0])\n"]}],"source":["train = data_cleaning(train)"]},{"cell_type":"code","execution_count":7,"id":"087d384c","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.484263Z","iopub.status.busy":"2024-02-09T12:05:59.48397Z","iopub.status.idle":"2024-02-09T12:05:59.495194Z","shell.execute_reply":"2024-02-09T12:05:59.494157Z"},"papermill":{"duration":0.023457,"end_time":"2024-02-09T12:05:59.497037","exception":false,"start_time":"2024-02-09T12:05:59.47358","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8693 entries, 0 to 8692\n","Data columns (total 14 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   HomePlanet    8693 non-null   int64  \n"," 1   CryoSleep     8693 non-null   bool   \n"," 2   Destination   8693 non-null   int64  \n"," 3   Age           8693 non-null   float64\n"," 4   VIP           8693 non-null   bool   \n"," 5   RoomService   8693 non-null   float64\n"," 6   FoodCourt     8693 non-null   float64\n"," 7   ShoppingMall  8693 non-null   float64\n"," 8   Spa           8693 non-null   float64\n"," 9   VRDeck        8693 non-null   float64\n"," 10  Transported   8693 non-null   bool   \n"," 11  Num           8693 non-null   int64  \n"," 12  Side          8693 non-null   int64  \n"," 13  group_size    8693 non-null   int64  \n","dtypes: bool(3), float64(6), int64(5)\n","memory usage: 772.6 KB\n"]}],"source":["train.info()"]},{"cell_type":"code","execution_count":8,"id":"7387fa48","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.51709Z","iopub.status.busy":"2024-02-09T12:05:59.516826Z","iopub.status.idle":"2024-02-09T12:05:59.535733Z","shell.execute_reply":"2024-02-09T12:05:59.534834Z"},"papermill":{"duration":0.031225,"end_time":"2024-02-09T12:05:59.537804","exception":false,"start_time":"2024-02-09T12:05:59.506579","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HomePlanet</th>\n","      <th>CryoSleep</th>\n","      <th>Destination</th>\n","      <th>Age</th>\n","      <th>VIP</th>\n","      <th>RoomService</th>\n","      <th>FoodCourt</th>\n","      <th>ShoppingMall</th>\n","      <th>Spa</th>\n","      <th>VRDeck</th>\n","      <th>Transported</th>\n","      <th>Num</th>\n","      <th>Side</th>\n","      <th>group_size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>39.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>24.0</td>\n","      <td>False</td>\n","      <td>109.0</td>\n","      <td>9.0</td>\n","      <td>25.0</td>\n","      <td>549.0</td>\n","      <td>44.0</td>\n","      <td>True</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>58.0</td>\n","      <td>True</td>\n","      <td>43.0</td>\n","      <td>3576.0</td>\n","      <td>0.0</td>\n","      <td>6715.0</td>\n","      <td>49.0</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>33.0</td>\n","      <td>False</td>\n","      <td>0.0</td>\n","      <td>1283.0</td>\n","      <td>371.0</td>\n","      <td>3329.0</td>\n","      <td>193.0</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>16.0</td>\n","      <td>False</td>\n","      <td>303.0</td>\n","      <td>70.0</td>\n","      <td>151.0</td>\n","      <td>565.0</td>\n","      <td>2.0</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   HomePlanet  CryoSleep  Destination   Age    VIP  RoomService  FoodCourt  \\\n","0           1      False            1  39.0  False          0.0        0.0   \n","1           2      False            1  24.0  False        109.0        9.0   \n","2           1      False            1  58.0   True         43.0     3576.0   \n","3           1      False            1  33.0  False          0.0     1283.0   \n","4           2      False            1  16.0  False        303.0       70.0   \n","\n","   ShoppingMall     Spa  VRDeck  Transported  Num  Side  group_size  \n","0           0.0     0.0     0.0        False    0     0           1  \n","1          25.0   549.0    44.0         True    0     1           1  \n","2           0.0  6715.0    49.0        False    0     1           2  \n","3         371.0  3329.0   193.0        False    0     1           2  \n","4         151.0   565.0     2.0         True    1     1           1  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"markdown","id":"56466da2","metadata":{"papermill":{"duration":0.009785,"end_time":"2024-02-09T12:05:59.557705","exception":false,"start_time":"2024-02-09T12:05:59.54792","status":"completed"},"tags":[]},"source":["### Data Preprocessing:  "]},{"cell_type":"markdown","id":"9e38fc89","metadata":{"papermill":{"duration":0.009467,"end_time":"2024-02-09T12:05:59.577061","exception":false,"start_time":"2024-02-09T12:05:59.567594","status":"completed"},"tags":[]},"source":["#### Feature Engineering:  \n","*Create new features from existing ones to improve model performance.*"]},{"cell_type":"code","execution_count":9,"id":"f9c121d8","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.597782Z","iopub.status.busy":"2024-02-09T12:05:59.597469Z","iopub.status.idle":"2024-02-09T12:05:59.601533Z","shell.execute_reply":"2024-02-09T12:05:59.600732Z"},"papermill":{"duration":0.016757,"end_time":"2024-02-09T12:05:59.603344","exception":false,"start_time":"2024-02-09T12:05:59.586587","status":"completed"},"tags":[]},"outputs":[],"source":["#### feature engineering (add to clean_data() for convenience)\n","# ######################### feature engineering ##########################\n","# # split the 'Cabin' column into 'Deck', 'Num', and 'Side'\n","# df[['Deck', 'Num', 'Side']] = df['Cabin'].str.split('/', expand=True)\n","# # fill NaN values in 'Side' with the mode of the 'Side' column\n","# df['Side'] = df['Side'].fillna(df['Side'].mode()[0])\n","# # map 'P' to Port (0) and 'S' to Starboard (1)\n","# df['Side'] = df['Side'].map({'P': 0, 'S': 1})\n","# # perform one-hot encoding on 'HomePlanet' and 'Destination' columns\n","# df = pd.get_dummies(df, columns=['HomePlanet', 'Destination'])\n","# # extract the group identifier from 'PassengerId'\n","# group = df['PassengerId'].str.split('_').str[0]\n","# # create a dictionary with group counts\n","# group_size_dict = group.value_counts().to_dict()\n","# # map the group size to each passenger\n","# df['group_size'] = group.map(group_size_dict)\n","# # drop 'Name' and 'Cabin' columns from the DataFrame\n","# df = df.drop(['PassengerId', 'Name', 'Cabin', 'Num', 'Deck'], axis=1)"]},{"cell_type":"markdown","id":"52d7edf7","metadata":{"papermill":{"duration":0.009306,"end_time":"2024-02-09T12:05:59.622222","exception":false,"start_time":"2024-02-09T12:05:59.612916","status":"completed"},"tags":[]},"source":["#### Data Transformation:  \n","*Normalize, scale, or encode data as necessary.*"]},{"cell_type":"code","execution_count":10,"id":"357b213d","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.642328Z","iopub.status.busy":"2024-02-09T12:05:59.642043Z","iopub.status.idle":"2024-02-09T12:05:59.666156Z","shell.execute_reply":"2024-02-09T12:05:59.665509Z"},"papermill":{"duration":0.0364,"end_time":"2024-02-09T12:05:59.668118","exception":false,"start_time":"2024-02-09T12:05:59.631718","status":"completed"},"tags":[]},"outputs":[],"source":["# prepare feature and target\n","X = train.drop(['Transported'], axis=1)\n","y = train['Transported']\n","# split data into 80% train and 20% test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","# initialize the scaler\n","scaler = StandardScaler()\n","# fit the scaler with train set (X_train)\n","scaler.fit(X_train)\n","# apply the scaler to train set (X_train) and validation set (X_test)\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"markdown","id":"fc4bf024","metadata":{"papermill":{"duration":0.009287,"end_time":"2024-02-09T12:05:59.686997","exception":false,"start_time":"2024-02-09T12:05:59.67771","status":"completed"},"tags":[]},"source":["### Data Modeling:  \n","*Conduct a comprehensive assessment by deploying a suite of classification algorithms, such as K-Nearest Neighbors (KNN), Logistic Regression, and Random Forest, to ensure a robust evaluation of the dataset's predictive dynamics.*"]},{"cell_type":"code","execution_count":11,"id":"d71fd263","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.707333Z","iopub.status.busy":"2024-02-09T12:05:59.70704Z","iopub.status.idle":"2024-02-09T12:05:59.713223Z","shell.execute_reply":"2024-02-09T12:05:59.712388Z"},"papermill":{"duration":0.018273,"end_time":"2024-02-09T12:05:59.715011","exception":false,"start_time":"2024-02-09T12:05:59.696738","status":"completed"},"tags":[]},"outputs":[],"source":["def save_model_predictions_to_csv(model, test_dataset, scaler, output_filename='submission.csv'):\n","    \n","    try:\n","        # save the 'PassengerId' column\n","        PassengerId = test_dataset['PassengerId']\n","        # clean the dataset\n","        test_dataset = data_cleaning(test_dataset)\n","        test_dataset = scaler.transform(test_dataset)\n","        # make predictions using the provided model\n","        y_pred = model.predict(test_dataset)\n","\n","        # create a DataFrame with 'PassengerId' and the predictions\n","        submission_df = pd.DataFrame({\n","            'PassengerId': PassengerId,\n","            'Transported': y_pred\n","        })\n","\n","        # save the DataFrame to a CSV file\n","        submission_df.to_csv(output_filename, index=False)\n","        print(f\"Your submission was successfully saved to {output_filename}!\")\n","        \n","    except Exception as e:\n","        # handle any exceptions that might occur\n","        print(\"An error occurred while saving the submission:\")\n","        print(e)"]},{"cell_type":"markdown","id":"f5d4ea51","metadata":{"papermill":{"duration":0.009443,"end_time":"2024-02-09T12:05:59.734121","exception":false,"start_time":"2024-02-09T12:05:59.724678","status":"completed"},"tags":[]},"source":["#### KNN\n","The K-Nearest Neighbors algorithm boasts simplicity in its non-parametric and instance-based approach, excels at classifying non-linear data, and performs well with a small number of input variables."]},{"cell_type":"code","execution_count":12,"id":"367adec7","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.754575Z","iopub.status.busy":"2024-02-09T12:05:59.754112Z","iopub.status.idle":"2024-02-09T12:05:59.759648Z","shell.execute_reply":"2024-02-09T12:05:59.758748Z"},"papermill":{"duration":0.018109,"end_time":"2024-02-09T12:05:59.761839","exception":false,"start_time":"2024-02-09T12:05:59.74373","status":"completed"},"tags":[]},"outputs":[],"source":["def train_and_evaluate_knn(X_train, y_train, X_test, y_test, n_neighbors=3):\n","    \n","    '''Train a k-Nearest Neighbors classifier and evaluate its accuracy.'''\n","    \n","    # initialize the kNN classifier with specified number of neighbors\n","    knn = KNeighborsClassifier(n_neighbors)\n","    # train the classifier on the training data\n","    knn.fit(X_train, y_train)\n","    # make predictions on the testing data\n","    y_pred = knn.predict(X_test)\n","    # calculate the accuracy of the predictions\n","    accuracy = accuracy_score(y_test, y_pred)\n","    # display accuracy\n","    print(f'The accuracy is: {accuracy}')\n","    \n","    return knn"]},{"cell_type":"code","execution_count":13,"id":"8800e41b","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.782363Z","iopub.status.busy":"2024-02-09T12:05:59.782086Z","iopub.status.idle":"2024-02-09T12:05:59.785911Z","shell.execute_reply":"2024-02-09T12:05:59.784984Z"},"papermill":{"duration":0.016129,"end_time":"2024-02-09T12:05:59.787804","exception":false,"start_time":"2024-02-09T12:05:59.771675","status":"completed"},"tags":[]},"outputs":[],"source":["# #### implement K-fold cross-validation to choose the optimal K\n","# knn = KNeighborsClassifier()\n","# # define the parameter grid\n","# param_grid = {'n_neighbors': range(1, 31)}\n","# # use GridSearchCV\n","# grid_search = GridSearchCV(knn, param_grid, cv=5) # cv is the number of folds\n","# # fit the grid search to the data\n","# grid_search.fit(X_train, y_train)\n","# # get the best parameter\n","# best_k = grid_search.best_params_['n_neighbors']\n","# print(f\"The best value for 'k' is {best_k}\")"]},{"cell_type":"code","execution_count":14,"id":"cd82f871","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:05:59.808003Z","iopub.status.busy":"2024-02-09T12:05:59.807769Z","iopub.status.idle":"2024-02-09T12:06:00.896084Z","shell.execute_reply":"2024-02-09T12:06:00.895159Z"},"papermill":{"duration":1.100752,"end_time":"2024-02-09T12:06:00.898193","exception":false,"start_time":"2024-02-09T12:05:59.797441","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The accuracy is: 0.7827586206896552\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_27/3849463590.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df[feature] = df[feature].fillna(df[feature].mode()[0])\n"]},{"name":"stdout","output_type":"stream","text":["Your submission was successfully saved to submission.csv!\n"]}],"source":["knn = train_and_evaluate_knn(X_train, y_train, X_test, y_test, 30)\n","save_model_predictions_to_csv(knn, test, scaler)"]},{"cell_type":"markdown","id":"e41e80ed","metadata":{"papermill":{"duration":0.009817,"end_time":"2024-02-09T12:06:00.918105","exception":false,"start_time":"2024-02-09T12:06:00.908288","status":"completed"},"tags":[]},"source":["#### Logistic Regression\n","Logistic Regression offers a probabilistic understanding of class membership, excels with binary classification tasks, and maintains efficiency with resource use, making it a preferred model for its interpretability and speed in scenarios with dichotomous outcomes."]},{"cell_type":"code","execution_count":15,"id":"20d39321","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:06:00.939401Z","iopub.status.busy":"2024-02-09T12:06:00.938768Z","iopub.status.idle":"2024-02-09T12:06:00.945753Z","shell.execute_reply":"2024-02-09T12:06:00.944833Z"},"papermill":{"duration":0.019973,"end_time":"2024-02-09T12:06:00.948019","exception":false,"start_time":"2024-02-09T12:06:00.928046","status":"completed"},"tags":[]},"outputs":[],"source":["def train_and_evaluate_logreg(X_train, y_train, X_test, y_test):\n","    '''Train a logistic regression classifier and evaluate its accuracy.'''\n","    \n","    # initialize the logistic model\n","    logreg = LogisticRegression()\n","    # fit the model to the training data\n","    logreg.fit(X_train, y_train)\n","    # predict probabilities\n","    y_pred = logreg.predict(X_test)\n","    # calculate the accuracy of the model\n","    accuracy = accuracy_score(y_test, y_pred)\n","\n","    # evaluate accuracy\n","    print('#' * 50)\n","    print(f\"Accuracy:\\n {accuracy: .2f}\")\n","\n","    # evaluate classification report\n","    print('#' * 50)\n","    print(f\"classification report:\\n {classification_report(y_test, y_pred)}\")\n","    \n","    # access the model's coefficients and intercept\n","    coefficients = logreg.coef_\n","    intercept = logreg.intercept_\n","    # matching the coefficients to the feature names\n","    feature_importance = pd.DataFrame(data=coefficients.T, index=X.columns, columns=['Coefficient'])\n","    print('#' * 50)\n","    print(f\"feature importance:\\n {feature_importance}\")\n","    \n","    return logreg"]},{"cell_type":"code","execution_count":16,"id":"99826888","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:06:00.969196Z","iopub.status.busy":"2024-02-09T12:06:00.968934Z","iopub.status.idle":"2024-02-09T12:06:01.032473Z","shell.execute_reply":"2024-02-09T12:06:01.031121Z"},"papermill":{"duration":0.077658,"end_time":"2024-02-09T12:06:01.035857","exception":false,"start_time":"2024-02-09T12:06:00.958199","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["##################################################\n","Accuracy:\n","  0.75\n","##################################################\n","classification report:\n","               precision    recall  f1-score   support\n","\n","       False       0.78      0.72      0.75       443\n","        True       0.73      0.79      0.76       427\n","\n","    accuracy                           0.75       870\n","   macro avg       0.76      0.75      0.75       870\n","weighted avg       0.76      0.75      0.75       870\n","\n","##################################################\n","feature importance:\n","               Coefficient\n","HomePlanet      -0.236909\n","CryoSleep        0.800497\n","Destination      0.171908\n","Age             -0.018787\n","VIP              0.052130\n","RoomService     -0.818237\n","FoodCourt        1.069406\n","ShoppingMall     0.431736\n","Spa             -1.897077\n","VRDeck          -1.776285\n","Num             -0.033014\n","Side             0.293276\n","group_size       0.096323\n"]}],"source":["logreg = train_and_evaluate_logreg(X_train, y_train, X_test, y_test)\n","# save_model_predictions_to_csv(logreg, test, scaler)"]},{"cell_type":"markdown","id":"a7347ada","metadata":{"papermill":{"duration":0.020829,"end_time":"2024-02-09T12:06:01.079107","exception":false,"start_time":"2024-02-09T12:06:01.058278","status":"completed"},"tags":[]},"source":["#### random forest\n","Random Forest is a versatile algorithm that can handle both classification and regression tasks with high accuracy, manages large datasets with thousands of input variables without variable deletion, and provides important measures of feature significance, all while being less prone to overfitting compared to individual decision trees."]},{"cell_type":"code","execution_count":17,"id":"5dc4bc3f","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:06:01.123518Z","iopub.status.busy":"2024-02-09T12:06:01.123034Z","iopub.status.idle":"2024-02-09T12:06:01.131658Z","shell.execute_reply":"2024-02-09T12:06:01.130549Z"},"papermill":{"duration":0.034524,"end_time":"2024-02-09T12:06:01.135158","exception":false,"start_time":"2024-02-09T12:06:01.100634","status":"completed"},"tags":[]},"outputs":[],"source":["def train_and_evaluate_rf(X_train, y_train, X_test, y_test):\n","    '''Train a random forest classifier and evaluate its accuracy.'''\n","    \n","    # initialize the Random Forest model\n","    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    # fit the model to the training data\n","    rf.fit(X_train, y_train)\n","    # predict class\n","    y_pred = rf.predict(X_test)\n","\n","    # evaluate accuracy\n","    print(f\"Accuracy:\\n {accuracy_score(y_test, y_pred)}\")\n","    # detailed classification report\n","    print(f\"classification report:\\n {classification_report(y_test, y_pred)}\")\n","    \n","    return rf"]},{"cell_type":"code","execution_count":18,"id":"d813654e","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:06:01.157807Z","iopub.status.busy":"2024-02-09T12:06:01.157562Z","iopub.status.idle":"2024-02-09T12:06:02.257609Z","shell.execute_reply":"2024-02-09T12:06:02.25669Z"},"papermill":{"duration":1.11292,"end_time":"2024-02-09T12:06:02.259625","exception":false,"start_time":"2024-02-09T12:06:01.146705","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:\n"," 0.764367816091954\n","classification report:\n","               precision    recall  f1-score   support\n","\n","       False       0.77      0.76      0.77       443\n","        True       0.76      0.77      0.76       427\n","\n","    accuracy                           0.76       870\n","   macro avg       0.76      0.76      0.76       870\n","weighted avg       0.76      0.76      0.76       870\n","\n"]}],"source":["rf = train_and_evaluate_rf(X_train, y_train, X_test, y_test)\n","# save_model_predictions_to_csv(rf, test, scaler)"]},{"cell_type":"markdown","id":"6e163c45","metadata":{"papermill":{"duration":0.00978,"end_time":"2024-02-09T12:06:02.280054","exception":false,"start_time":"2024-02-09T12:06:02.270274","status":"completed"},"tags":[]},"source":["#### Deep Learning\n","Deep Neural Networks excel in handling complex patterns within vast datasets, often surpassing human-level performance in tasks with large feature spaces (thousands to millions), and are highly adaptable through their deep architecture and ability to learn feature representations automatically."]},{"cell_type":"code","execution_count":19,"id":"742888e5","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:06:02.30191Z","iopub.status.busy":"2024-02-09T12:06:02.301639Z","iopub.status.idle":"2024-02-09T12:06:02.375339Z","shell.execute_reply":"2024-02-09T12:06:02.374273Z"},"papermill":{"duration":0.086779,"end_time":"2024-02-09T12:06:02.377337","exception":false,"start_time":"2024-02-09T12:06:02.290558","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Feature batch shape: torch.Size([64, 13])\n","Labels batch shape: torch.Size([64])\n"]}],"source":["#### create a custom dataset class that inherits torch.utils.data.Dataset\n","# create TabularDataset class in order to use DataLoader\n","class TabularDataset(Dataset):\n","    def __init__(self, features, labels):\n","        self.features = torch.tensor(features, dtype=torch.float32)\n","        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.features)\n","    \n","    def __getitem__(self, index):\n","        return self.features[index], self.labels[index]\n","\n","# create PyTorch Dataset objects\n","train_dataset = TabularDataset(X_train, y_train)\n","test_dataset = TabularDataset(X_test, y_test)\n","\n","# create DataLoaders\n","# in each epoch, the train process iterate each bach until all samples are calculated\n","train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n","\n","# create an iterator over the dataset\n","train_iter = iter(train_loader)\n","# get the next batch\n","features, labels = next(train_iter)\n","# print the shapes\n","print(f'Feature batch shape: {features.size()}')\n","print(f'Labels batch shape: {labels.size()}')"]},{"cell_type":"code","execution_count":20,"id":"94f89ec4","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:06:02.400636Z","iopub.status.busy":"2024-02-09T12:06:02.39993Z","iopub.status.idle":"2024-02-09T12:06:02.406967Z","shell.execute_reply":"2024-02-09T12:06:02.406247Z"},"papermill":{"duration":0.01988,"end_time":"2024-02-09T12:06:02.408777","exception":false,"start_time":"2024-02-09T12:06:02.388897","status":"completed"},"tags":[]},"outputs":[],"source":["#### define the model\n","class ClassificationModel(nn.Module):\n","    def __init__(self, num_features, num_classes=1):  # default num_classes to 1 for binary classification\n","        super().__init__()\n","        self.sequential1 = nn.Sequential(\n","            nn.Linear(num_features, 64),\n","            nn.ReLU()\n","        )\n","        self.sequential2 = nn.Sequential(\n","            nn.Linear(64, 48),\n","            nn.ReLU()\n","        )\n","        self.sequential3 = nn.Sequential(\n","            nn.Linear(48, 32),\n","            nn.ReLU()\n","        )\n","        self.output_layer = nn.Linear(32, num_classes) \n","\n","    def forward(self, x):\n","        x = self.sequential1(x)\n","        x = self.sequential2(x)\n","        x = self.sequential3(x)\n","        x = torch.sigmoid(self.output_layer(x))  # using sigmoid for binary classification\n","        return x"]},{"cell_type":"code","execution_count":21,"id":"c9f158aa","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:06:02.431192Z","iopub.status.busy":"2024-02-09T12:06:02.430726Z","iopub.status.idle":"2024-02-09T12:06:02.439851Z","shell.execute_reply":"2024-02-09T12:06:02.439153Z"},"papermill":{"duration":0.022274,"end_time":"2024-02-09T12:06:02.441754","exception":false,"start_time":"2024-02-09T12:06:02.41948","status":"completed"},"tags":[]},"outputs":[],"source":["#### define the model 2\n","class ClassificationModel_2(nn.Module):\n","    def __init__(self, num_features, num_classes=1, dropout_rate=0.5):\n","        super().__init__()\n","        self.layer1 = nn.Linear(num_features, 64)\n","        self.batch_norm1 = nn.BatchNorm1d(64)\n","        self.dropout1 = nn.Dropout(dropout_rate)\n","        \n","        self.layer2 = nn.Linear(64, 48)\n","        self.batch_norm2 = nn.BatchNorm1d(48)\n","        self.dropout2 = nn.Dropout(dropout_rate)\n","        \n","        self.layer3 = nn.Linear(48, 32)\n","        self.batch_norm3 = nn.BatchNorm1d(32)\n","        self.dropout3 = nn.Dropout(dropout_rate)\n","        \n","        self.output_layer = nn.Linear(32, num_classes)\n","        \n","    def forward(self, x):\n","        x = F.relu(self.batch_norm1(self.layer1(x)))\n","        x = self.dropout1(x)\n","        \n","        x = F.relu(self.batch_norm2(self.layer2(x)))\n","        x = self.dropout2(x)\n","        \n","        x = F.relu(self.batch_norm3(self.layer3(x)))\n","        x = self.dropout3(x)\n","        \n","        x = torch.sigmoid(self.output_layer(x))  # still using sigmoid for binary classification\n","        return x"]},{"cell_type":"code","execution_count":22,"id":"6d5d49a8","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:06:02.463675Z","iopub.status.busy":"2024-02-09T12:06:02.463439Z","iopub.status.idle":"2024-02-09T12:11:59.916854Z","shell.execute_reply":"2024-02-09T12:11:59.915883Z"},"papermill":{"duration":357.477877,"end_time":"2024-02-09T12:11:59.929846","exception":false,"start_time":"2024-02-09T12:06:02.451969","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000, Loss: 0.6933493943718391\n","Epoch 101/1000, Loss: 0.5968037296116837\n","Epoch 201/1000, Loss: 0.5933174224403815\n","Epoch 301/1000, Loss: 0.5900514915706666\n","Epoch 401/1000, Loss: 0.5931730885815815\n","Epoch 501/1000, Loss: 0.5908882942626147\n","Epoch 601/1000, Loss: 0.589815760046486\n","Epoch 701/1000, Loss: 0.5913383728120385\n","Epoch 801/1000, Loss: 0.5884961626394009\n","Epoch 901/1000, Loss: 0.5905789345260558\n","Accuracy of the model on the test data: 76.55%\n"]}],"source":["# create an instance of the ClassificationModel with the number of features from training data\n","model = ClassificationModel_2(num_features=X_train.shape[1])\n","\n","# use BCEWithLogitsLoss which combines a sigmoid layer and the BCELoss in one single class\n","criterion = nn.BCEWithLogitsLoss()\n","# initialize the optimizer with the Adam algorithm and a learning rate of 0.001\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# set the device to cuda if available, otherwise use cpu\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# transfer the model to the chosen device\n","model.to(device)\n","\n","# set the number of epochs for training\n","num_epochs = 1000\n","\n","# start the training loop\n","for epoch in range(num_epochs):\n","    # set the model to training mode\n","    model.train()\n","    # initialize the total loss variable\n","    total_loss = 0\n","\n","    # iterate over batches of data from the train_loader\n","    for inputs, labels in train_loader:\n","        # transfer inputs and labels to the device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # reset the gradients of the model parameters\n","        optimizer.zero_grad()\n","        # forward pass: compute the model outputs\n","        outputs = model(inputs)\n","        # calculate the loss between outputs and labels\n","        loss = criterion(outputs, labels.unsqueeze(1))\n","        # backward pass: compute the gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # add the current loss to the total loss\n","        total_loss += loss.item()\n","        # update the model parameters\n","        optimizer.step()\n","    \n","    # print the loss every 100 epochs\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")\n","\n","# switch off gradients for validation, saves memory and computations\n","with torch.no_grad():\n","    # set the model to evaluation mode\n","    model.eval()\n","    # initialize correct prediction count\n","    correct = 0\n","    # initialize total prediction count\n","    total = 0\n","\n","    # iterate over batches of data from the test_loader\n","    for inputs, labels in test_loader:\n","        # transfer inputs and labels to the device\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        # forward pass: compute the model outputs\n","        outputs = model(inputs)\n","        # convert outputs probabilities to predicted class (0 or 1)\n","        predicted = outputs.round()\n","        # count the total number of labels\n","        total += labels.size(0)\n","        # count the number of correct predictions\n","        correct += (predicted == labels.unsqueeze(1)).sum().item()\n","\n","# calculate the accuracy of predictions\n","accuracy = (correct / total) * 100\n","# print the accuracy of the model on the test data\n","print(f'Accuracy of the model on the test data: {accuracy:.2f}%')"]},{"cell_type":"code","execution_count":23,"id":"df259ca3","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:11:59.953394Z","iopub.status.busy":"2024-02-09T12:11:59.952917Z","iopub.status.idle":"2024-02-09T12:11:59.960318Z","shell.execute_reply":"2024-02-09T12:11:59.959387Z"},"papermill":{"duration":0.021275,"end_time":"2024-02-09T12:11:59.96231","exception":false,"start_time":"2024-02-09T12:11:59.941035","status":"completed"},"tags":[]},"outputs":[],"source":["def save_model_predictions_to_csv(model, test_dataset, scaler, output_filename='submission.csv'):\n","    \n","    try:\n","        # save the 'PassengerId' column\n","        PassengerId = test_dataset['PassengerId']\n","        # clean the dataset\n","        test_dataset = data_cleaning(test_dataset)\n","        test_dataset = scaler.transform(test_dataset)\n","        # make predictions using the provided model\n","        y_pred = model(torch.tensor(test_dataset, dtype=torch.float32).to(device))\n","        y_pred = y_pred.round().int()\n","        y_pred = y_pred.detach().cpu().numpy().flatten()\n","\n","        # create a DataFrame with 'PassengerId' and the predictions\n","        submission_df = pd.DataFrame({\n","            'PassengerId': PassengerId,\n","            'Transported': y_pred\n","        })\n","\n","        # save the DataFrame to a CSV file\n","        submission_df.to_csv(output_filename, index=False)\n","        print(f\"Your submission was successfully saved to {output_filename}!\")\n","        \n","    except Exception as e:\n","        # handle any exceptions that might occur\n","        print(\"An error occurred while saving the submission:\")\n","        print(e)"]},{"cell_type":"code","execution_count":24,"id":"4570fbbd","metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:11:59.986615Z","iopub.status.busy":"2024-02-09T12:11:59.986353Z","iopub.status.idle":"2024-02-09T12:11:59.990405Z","shell.execute_reply":"2024-02-09T12:11:59.989475Z"},"papermill":{"duration":0.018802,"end_time":"2024-02-09T12:11:59.992509","exception":false,"start_time":"2024-02-09T12:11:59.973707","status":"completed"},"tags":[]},"outputs":[],"source":["# save_model_predictions_to_csv(model, test, scaler)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":3220602,"sourceId":34377,"sourceType":"competition"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":370.781532,"end_time":"2024-02-09T12:12:01.626817","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-09T12:05:50.845285","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}